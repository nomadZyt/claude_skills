import json
import re
from typing import List, Dict, Optional
from collections import defaultdict
from pathlib import Path


# å·¥ä½œç±»å‹åˆ†ç±»è§„åˆ™ï¼ˆåŸºäº CLASSIFICATION.mdï¼‰
CLASSIFICATION_RULES = {
    'éœ€æ±‚å¼€å‘': {
        'keywords': ['feat', 'feature', 'æ–°å¢', 'æ”¯æŒ', 'add', 'implement', 'feat', 'init'],
        'description': 'ç›´æ¥äº¤ä»˜ä¸šåŠ¡èƒ½åŠ›æˆ–ç”¨æˆ·åŠŸèƒ½'
    },
    'Bug ä¿®å¤': {
        'keywords': ['fix', 'bug', 'ä¿®å¤', 'é—®é¢˜', 'issue', 'bugfix'],
        'description': 'ä¿®å¤å·²çŸ¥é—®é¢˜æˆ–çº¿ä¸Šç¼ºé™·'
    },
    'æŠ€æœ¯å€º / é‡æ„ / ä¼˜åŒ–': {
        'keywords': ['refactor', 'optimize', 'clean', 'é‡æ„', 'ä¼˜åŒ–', 'æ”¹è¿›', 'improve'],
        'description': 'ä¸ç›´æ¥æ”¹å˜ä¸šåŠ¡èƒ½åŠ›ï¼Œæå‡ä»£ç è´¨é‡ã€ç»“æ„æˆ–æ€§èƒ½'
    },
    'æ”¯æ’‘æ€§å·¥ä½œ': {
        'keywords': ['é…ç½®', 'CI', 'è„šæ‰‹æ¶', 'ä¾èµ–å‡çº§', 'config', 'setup', 'upgrade', 'deps'],
        'description': 'ä¸ºä¸šåŠ¡æˆ–å›¢é˜Ÿæä¾›ä¿éšœï¼Œä½†ä¸ç›´æ¥äº¤ä»˜åŠŸèƒ½'
    },
    'åä½œ / åˆå¹¶': {
        'keywords': ['merge', 'sync', 'chore', 'åˆå¹¶', 'åŒæ­¥'],
        'description': 'éä¸»è¦äº§å‡ºå‹å·¥ä½œ'
    }
}


# å…œåº•æ˜ å°„è§„åˆ™ï¼ˆåŸºäº MODULE_MAPPING.mdï¼‰
FALLBACK_MAPPING = {
    'NFC æŒªè½¦ç ': {
        'repo_contains': ['nfc'],
        'path_contains': ['/nfc/']
    }
}


def classify_commit(commit_message: str, paths: List[str] = None) -> str:
    """
    åˆ†ç±» commit çš„å·¥ä½œç±»å‹
    
    Args:
        commit_message: commit æ¶ˆæ¯
        paths: æ¶‰åŠçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    
    Returns:
        å·¥ä½œç±»å‹åˆ†ç±»
    """
    message_lower = commit_message.lower()
    
    # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥åˆ†ç±»è§„åˆ™
    for category, rule in CLASSIFICATION_RULES.items():
        for keyword in rule['keywords']:
            if keyword.lower() in message_lower:
                return category
    
    # æ ¹æ®è·¯å¾„ç‰¹å¾åˆ¤æ–­ï¼ˆå¯é€‰ï¼‰
    if paths:
        path_str = ' '.join(paths).lower()
        # å¦‚æœæ¶‰åŠé…ç½®æ–‡ä»¶ã€CI æ–‡ä»¶ç­‰ï¼Œå¯èƒ½æ˜¯æ”¯æ’‘æ€§å·¥ä½œ
        if any(kw in path_str for kw in ['config', 'ci', '.yml', '.yaml', 'package.json', 'requirements.txt']):
            return 'æ”¯æ’‘æ€§å·¥ä½œ'
    
    # é»˜è®¤å½’ç±»ä¸ºæ”¯æ’‘æ€§å·¥ä½œ
    return 'æ”¯æ’‘æ€§å·¥ä½œ'


def identify_project(commit: Dict, fallback_mapping: Dict = None) -> str:
    """
    è¯†åˆ«é¡¹ç›®åç§°ï¼ˆåŸºäº MODULE_MAPPING.md è§„åˆ™ï¼‰
    
    ä¼˜å…ˆçº§ï¼š
    1. ä»“åº“å = é¡¹ç›®åï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
    2. ä»“åº“å†…ä¸»ç›®å½•å
    3. commit message ä¸­çš„æ˜¾å¼å…³é”®è¯
    4. å…œåº•æ˜ å°„è§„åˆ™
    
    Args:
        commit: commit å­—å…¸ï¼ŒåŒ…å« repo, paths, message
        fallback_mapping: å…œåº•æ˜ å°„è§„åˆ™
    
    Returns:
        é¡¹ç›®åç§°
    """
    repo = commit.get('repo', '')
    paths = commit.get('paths', [])
    message = commit.get('message', '')
    
    # ä¼˜å…ˆçº§1: ä»“åº“åç›´æ¥ä½œä¸ºé¡¹ç›®åï¼ˆé»˜è®¤ç­–ç•¥ï¼‰
    if repo:
        # å…ˆæ£€æŸ¥å…œåº•æ˜ å°„
        if fallback_mapping:
            for project_name, rules in fallback_mapping.items():
                # æ£€æŸ¥ä»“åº“åæ˜¯å¦åŒ¹é…
                if any(keyword in repo.lower() for keyword in rules.get('repo_contains', [])):
                    return project_name
                # æ£€æŸ¥è·¯å¾„æ˜¯å¦åŒ¹é…
                if any(keyword in '/'.join(paths).lower() for keyword in rules.get('path_contains', [])):
                    return project_name
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…å…œåº•è§„åˆ™ï¼Œä½¿ç”¨ä»“åº“å
        return repo
    
    # ä¼˜å…ˆçº§2: ä»è·¯å¾„æå–ä¸»ç›®å½•å
    if paths:
        main_dirs = set()
        for path in paths:
            parts = Path(path).parts
            if len(parts) > 0:
                main_dirs.add(parts[0])
        if main_dirs:
            # è¿”å›æœ€å¸¸è§çš„ç›®å½•å
            return list(main_dirs)[0]
    
    # ä¼˜å…ˆçº§3: ä» commit message æå–ï¼ˆç®€å•å®ç°ï¼‰
    # è¿™é‡Œå¯ä»¥æ‰©å±•æ›´å¤æ‚çš„æå–é€»è¾‘
    
    return 'æœªçŸ¥é¡¹ç›®'


def should_merge_commit(commit: Dict) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆå¹¶æˆ–å¼±åŒ–æ˜¾ç¤ºçš„ commit
    """
    category = commit.get('category', '')
    message = commit.get('message', '').lower()
    
    # åä½œ/åˆå¹¶ç±»é»˜è®¤å¼±åŒ–
    if category == 'åä½œ / åˆå¹¶':
        return True
    
    # merge/sync/chore ç±»æäº¤
    if any(kw in message for kw in ['merge', 'sync', 'chore', 'åˆå¹¶', 'åŒæ­¥']):
        return True
    
    return False


def deduplicate_and_merge(commits: List[Dict]) -> List[Dict]:
    """
    å»å™ªå’Œåˆå¹¶ç›¸ä¼¼çš„ commits
    
    Args:
        commits: åŸå§‹ commits åˆ—è¡¨
    
    Returns:
        å¤„ç†åçš„ commits åˆ—è¡¨
    """
    # æŒ‰é¡¹ç›®å’Œå·¥ä½œç±»å‹åˆ†ç»„
    grouped = defaultdict(list)
    
    for commit in commits:
        # è·³è¿‡åº”è¯¥åˆå¹¶çš„ commitï¼ˆå¯é€‰ï¼šå¯ä»¥åˆå¹¶æ˜¾ç¤ºï¼‰
        if should_merge_commit(commit):
            # ä»ç„¶ä¿ç•™ï¼Œä½†æ ‡è®°ä¸ºå¼±åŒ–
            commit['_weak'] = True
        else:
            commit['_weak'] = False
        
        key = (commit.get('project', ''), commit.get('category', ''))
        grouped[key].append(commit)
    
    # å¯¹äºåŒä¸€é¡¹ç›®åŒä¸€ç±»å‹çš„å¤šä¸ª commitsï¼Œå¯ä»¥åˆå¹¶æè¿°
    merged_commits = []
    for (project, category), group_commits in grouped.items():
        if len(group_commits) == 1:
            merged_commits.append(group_commits[0])
        else:
            # å¤šä¸ª commits å¯ä»¥åˆå¹¶ä¸ºä¸€ä¸ªæ¡ç›®
            # è¿™é‡Œä¿ç•™æ‰€æœ‰ï¼Œä½†åœ¨æ¸²æŸ“æ—¶å¯ä»¥åˆå¹¶æ˜¾ç¤º
            merged_commits.extend(group_commits)
    
    return merged_commits


def enrich_commits(commits: List[Dict], fallback_mapping: Dict = None, repo_paths_map: Dict[str, str] = None) -> List[Dict]:
    """
    ä¸°å¯Œ commits ä¿¡æ¯ï¼šé¡¹ç›®è¯†åˆ«ã€å·¥ä½œåˆ†ç±»ã€ä»£ç æµç¨‹æ¢³ç†ã€ä»·å€¼æŠ½è±¡
    
    Args:
        commits: åŸå§‹ commits åˆ—è¡¨
        fallback_mapping: å…œåº•æ˜ å°„è§„åˆ™
        repo_paths_map: ä»“åº“è·¯å¾„æ˜ å°„ {repo_name: repo_path}
    
    Returns:
        ä¸°å¯Œåçš„ commits åˆ—è¡¨
    """
    enriched = []
    
    for commit in commits:
        # é¡¹ç›®è¯†åˆ«
        commit['project'] = identify_project(commit, fallback_mapping)
        
        # å·¥ä½œåˆ†ç±»
        commit['category'] = classify_commit(
            commit.get('message', ''),
            commit.get('paths', [])
        )
        
        # ä»£ç æµç¨‹æ¢³ç†ï¼ˆåŒ…å«å…³é”®ä»£ç æå–ï¼‰
        repo_name = commit.get('repo', '')
        repo_path = repo_paths_map.get(repo_name, None) if repo_paths_map else None
        code_flow_info = extract_code_flow(commit, repo_path)
        commit['code_flow'] = code_flow_info.get('description', '')
        commit['code_snippets'] = code_flow_info.get('code_snippets', [])
        
        # ä»·å€¼æŠ½è±¡
        commit['value'] = abstract_value(commit)
        
        enriched.append(commit)
    
    # å»å™ªå’Œåˆå¹¶
    enriched = deduplicate_and_merge(enriched)
    
    return enriched


def extract_code_snippets(commit: Dict, repo_path: str = None) -> List[Dict]:
    """
    ä» commit ä¸­æå–å…³é”®ä»£ç ç‰‡æ®µ
    
    Args:
        commit: commit å­—å…¸ï¼ŒåŒ…å« hash, paths, message
        repo_path: ä»“åº“è·¯å¾„ï¼ˆç”¨äºè¯»å–æ–‡ä»¶å†…å®¹ï¼‰
    
    Returns:
        ä»£ç ç‰‡æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªç‰‡æ®µåŒ…å« {file, lines, code}
    """
    import subprocess
    
    snippets = []
    commit_hash = commit.get('hash', '')
    paths = commit.get('paths', [])
    
    if not commit_hash or not paths or not repo_path:
        return snippets
    
    # åªå¤„ç†ä»£ç æ–‡ä»¶ï¼ˆæ’é™¤é…ç½®æ–‡ä»¶ã€æ ·å¼æ–‡ä»¶ç­‰ï¼‰
    code_extensions = ['.js', '.jsx', '.ts', '.tsx', '.py', '.java', '.go', '.rs', '.cpp', '.c']
    code_files = [p for p in paths if any(p.endswith(ext) for ext in code_extensions)]
    
    # é™åˆ¶å¤„ç†æ–‡ä»¶æ•°é‡ï¼Œé¿å…è¿‡å¤š
    for file_path in code_files[:3]:  # æœ€å¤šå¤„ç†3ä¸ªæ–‡ä»¶
        try:
            # ä½¿ç”¨ git show è·å–è¯¥æ–‡ä»¶åœ¨æ­¤ commit ä¸­çš„å˜æ›´
            cmd = ['git', '-C', repo_path, 'show', f'{commit_hash}:{file_path}']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
            
            if result.returncode == 0 and result.stdout:
                code = result.stdout
                # æå–å…³é”®ä»£ç ç‰‡æ®µï¼ˆå‡½æ•°å®šä¹‰ã€ç±»å®šä¹‰ç­‰ï¼‰
                lines = code.split('\n')
                
                # æŸ¥æ‰¾å…³é”®ä»£ç ï¼šå‡½æ•°å®šä¹‰ã€ç±»å®šä¹‰ã€é‡è¦é€»è¾‘
                key_lines = []
                for i, line in enumerate(lines[:100], 1):  # åªå¤„ç†å‰100è¡Œ
                    stripped = line.strip()
                    # æŸ¥æ‰¾å‡½æ•°/æ–¹æ³•å®šä¹‰
                    if any(stripped.startswith(kw) for kw in ['function ', 'const ', 'export ', 'class ', 'def ', 'async ']):
                        # æå–å‡½æ•°åŠå…¶åç»­å‡ è¡Œï¼ˆæœ€å¤š5è¡Œï¼‰
                        snippet_lines = lines[i-1:min(i+4, len(lines))]
                        if snippet_lines:
                            key_lines.append({
                                'line_num': i,
                                'code': '\n'.join(snippet_lines[:5])  # æœ€å¤š5è¡Œ
                            })
                            if len(key_lines) >= 2:  # æœ€å¤šæå–2ä¸ªå…³é”®ç‰‡æ®µ
                                break
                
                if key_lines:
                    snippets.append({
                        'file': Path(file_path).name,
                        'file_path': file_path,
                        'snippets': key_lines
                    })
        except Exception:
            # å¦‚æœè¯»å–å¤±è´¥ï¼Œè·³è¿‡è¯¥æ–‡ä»¶
            continue
    
    return snippets


def extract_code_flow(commit: Dict, repo_path: str = None) -> Dict:
    """
    æ¢³ç† commit çš„ä»£ç æµç¨‹ï¼Œæå–å…³é”®ä»£ç ä¿¡æ¯
    
    Args:
        commit: commit å­—å…¸ï¼ŒåŒ…å« hash, paths, message
        repo_path: ä»“åº“è·¯å¾„ï¼ˆå¯é€‰ï¼Œç”¨äºè¯»å–æ–‡ä»¶å†…å®¹ï¼‰
    
    Returns:
        åŒ…å«æµç¨‹æè¿°å’Œä»£ç ç‰‡æ®µçš„å­—å…¸
    """
    paths = commit.get('paths', [])
    message = commit.get('message', '')
    
    if not paths:
        return {'description': '', 'code_snippets': []}
    
    # åˆ†ææ–‡ä»¶è·¯å¾„ï¼Œæå–å…³é”®ä¿¡æ¯
    flow_parts = []
    
    # æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç±»
    components = [p for p in paths if any(kw in p.lower() for kw in ['component', 'page', 'view'])]
    utils = [p for p in paths if any(kw in p.lower() for kw in ['util', 'helper', 'tool', 'service', 'api'])]
    configs = [p for p in paths if any(kw in p.lower() for kw in ['config', 'constant', 'setting'])]
    styles = [p for p in paths if any(kw in p.lower() for kw in ['.css', '.scss', '.less', 'style'])]
    
    if components:
        flow_parts.append(f"ç»„ä»¶/é¡µé¢: {', '.join([Path(p).name for p in components[:3]])}")
    if utils:
        flow_parts.append(f"å·¥å…·/æœåŠ¡: {', '.join([Path(p).name for p in utils[:3]])}")
    if configs:
        flow_parts.append(f"é…ç½®: {', '.join([Path(p).name for p in configs[:2]])}")
    
    # ä» commit message æå–å…³é”®ä¿¡æ¯
    if 'feat' in message.lower() or 'æ–°å¢' in message:
        flow_parts.append("æ–°å¢åŠŸèƒ½å®ç°")
    elif 'fix' in message.lower() or 'ä¿®å¤' in message:
        flow_parts.append("é—®é¢˜ä¿®å¤")
    elif 'refactor' in message.lower() or 'é‡æ„' in message:
        flow_parts.append("ä»£ç é‡æ„")
    
    description = " | ".join(flow_parts) if flow_parts else "ä»£ç ä¿®æ”¹"
    
    # æå–å…³é”®ä»£ç ç‰‡æ®µï¼ˆå¦‚æœæä¾›äº†ä»“åº“è·¯å¾„ï¼‰
    code_snippets = []
    if repo_path:
        code_snippets = extract_code_snippets(commit, repo_path)
    
    return {
        'description': description,
        'code_snippets': code_snippets
    }


def abstract_value(commit: Dict) -> str:
    """
    å¯¹ commit è¿›è¡Œä»·å€¼æŠ½è±¡ï¼Œæå–ä¸šåŠ¡ä»·å€¼
    
    Args:
        commit: commit å­—å…¸ï¼ŒåŒ…å« category, message, paths
    
    Returns:
        ä»·å€¼æè¿°å­—ç¬¦ä¸²
    """
    category = commit.get('category', '')
    message = commit.get('message', '')
    paths = commit.get('paths', [])
    
    # æ ¹æ®åˆ†ç±»å’Œä»·å€¼å…³é”®è¯æå–ä»·å€¼
    value_keywords = {
        'éœ€æ±‚å¼€å‘': ['åŠŸèƒ½', 'æ”¯æŒ', 'æ–°å¢', 'å®ç°', 'ä¼˜åŒ–ä½“éªŒ', 'æå‡'],
        'Bug ä¿®å¤': ['ä¿®å¤', 'è§£å†³', 'æ”¹è¿›', 'æå‡ç¨³å®šæ€§'],
        'æŠ€æœ¯å€º / é‡æ„ / ä¼˜åŒ–': ['ä¼˜åŒ–', 'æå‡', 'æ”¹è¿›', 'å¢å¼º'],
        'æ”¯æ’‘æ€§å·¥ä½œ': ['ä¿éšœ', 'æ”¯æŒ', 'æå‡æ•ˆç‡']
    }
    
    # ä» message ä¸­æå–ä»·å€¼æè¿°
    message_lower = message.lower()
    
    # å°è¯•æå–ä¸­æ–‡ä»·å€¼æè¿°
    if category == 'éœ€æ±‚å¼€å‘':
        if any(kw in message for kw in ['æ”¯æŒ', 'æ–°å¢', 'å¢åŠ ', 'å®ç°', 'ä¼˜åŒ–ä½“éªŒ', 'æå‡', 'feat', 'feature', 'init', 'implement']):
            # æå–åŠŸèƒ½æè¿°
            for kw in ['æ”¯æŒ', 'æ–°å¢', 'å¢åŠ ', 'å®ç°', 'ä¼˜åŒ–', 'feat', 'feature', 'init', 'implement']:
                if kw in message:
                    idx = message.find(kw)
                    # æå–åç»­çš„æè¿°
                    desc = message[idx:idx+50] if len(message) > idx+50 else message[idx:]
                    return desc.strip()
        return "äº¤ä»˜æ–°åŠŸèƒ½ï¼Œæå‡ç”¨æˆ·ä½“éªŒ"
    
    elif category == 'Bug ä¿®å¤':
        if 'ä¿®å¤' in message or 'fix' in message_lower:
            return "ä¿®å¤é—®é¢˜ï¼Œæå‡ç³»ç»Ÿç¨³å®šæ€§"
        return "è§£å†³å·²çŸ¥é—®é¢˜"
    
    elif category == 'æŠ€æœ¯å€º / é‡æ„ / ä¼˜åŒ–':
        if 'ä¼˜åŒ–' in message or 'optimize' in message_lower:
            return "ä¼˜åŒ–ä»£ç ç»“æ„ï¼Œæå‡å¯ç»´æŠ¤æ€§"
        elif 'é‡æ„' in message or 'refactor' in message_lower:
            return "é‡æ„ä»£ç ï¼Œæå‡ä»£ç è´¨é‡"
        return "æŠ€æœ¯ä¼˜åŒ–ï¼Œæå‡ç³»ç»Ÿæ€§èƒ½"
    
    elif category == 'æ”¯æ’‘æ€§å·¥ä½œ':
        return "æ”¯æ’‘ä¸šåŠ¡å‘å±•ï¼Œæå‡å¼€å‘æ•ˆç‡"
    
    return "å®Œæˆå¼€å‘å·¥ä½œ"


def group_by_project_and_category(commits: List[Dict]) -> Dict[str, Dict[str, List[Dict]]]:
    """
    æŒ‰é¡¹ç›®å’Œåˆ†ç±»åˆ†ç»„ commits
    
    Returns:
        {é¡¹ç›®å: {åˆ†ç±»: [commits]}}
    """
    grouped = defaultdict(lambda: defaultdict(list))
    
    for commit in commits:
        project = commit.get('project', 'æœªçŸ¥é¡¹ç›®')
        category = commit.get('category', 'æœªçŸ¥åˆ†ç±»')
        grouped[project][category].append(commit)
    
    return dict(grouped)


def extract_commit_diff(commit: Dict, repo_path: str = None) -> List[Dict]:
    """
    æå–commitçš„diffä¿¡æ¯ï¼ŒåŒ…å«å…·ä½“çš„ä»£ç å˜æ›´å¯¹æ¯”

    Args:
        commit: commit å­—å…¸ï¼ŒåŒ…å« hash
        repo_path: ä»“åº“è·¯å¾„

    Returns:
        diffä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« {file, additions, deletions, diff_content}
    """
    import subprocess

    diff_info = []
    commit_hash = commit.get('hash', '')

    if not commit_hash or not repo_path:
        return diff_info

    try:
        # è·å–è¯¥commitçš„diffä¿¡æ¯
        cmd = ['git', '-C', repo_path, 'show', '--stat', '--format=', commit_hash]
        stat_result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)

        # è·å–è¯¦ç»†çš„diffå†…å®¹
        diff_cmd = ['git', '-C', repo_path, 'show', '--no-merges', commit_hash]
        diff_result = subprocess.run(diff_cmd, capture_output=True, text=True, timeout=15)

        if stat_result.returncode == 0 and diff_result.returncode == 0:
            # è§£æstatä¿¡æ¯
            stat_lines = stat_result.stdout.strip().split('\n')
            file_changes = {}

            for line in stat_lines:
                if '|' in line and ('+' in line or '-' in line):
                    parts = line.split('|')
                    if len(parts) >= 2:
                        file_path = parts[0].strip()
                        changes = parts[1].strip()

                        # è§£ææ·»åŠ å’Œåˆ é™¤çš„è¡Œæ•°
                        additions = changes.count('+')
                        deletions = changes.count('-')

                        file_changes[file_path] = {
                            'additions': additions,
                            'deletions': deletions,
                            'changes': changes
                        }

            # è§£ædiffå†…å®¹
            diff_content = diff_result.stdout

            # æŒ‰æ–‡ä»¶åˆ†ç»„diffå†…å®¹
            file_diffs = {}
            current_file = None
            current_diff = []

            for line in diff_content.split('\n'):
                if line.startswith('diff --git'):
                    # ä¿å­˜ä¸Šä¸€ä¸ªæ–‡ä»¶çš„diff
                    if current_file and current_diff:
                        file_diffs[current_file] = '\n'.join(current_diff)

                    # è§£ææ–°æ–‡ä»¶è·¯å¾„
                    parts = line.split()
                    if len(parts) >= 4:
                        current_file = parts[3][2:]  # ç§»é™¤ 'b/' å‰ç¼€
                        current_diff = []
                elif current_file:
                    # åªä¿ç•™æœ‰æ„ä¹‰çš„diffè¡Œï¼ˆè·³è¿‡æ–‡ä»¶å¤´ä¿¡æ¯ï¼‰
                    if line.startswith('@@') or line.startswith('+') or line.startswith('-'):
                        current_diff.append(line)
                    elif line.startswith('index') or line.startswith('---') or line.startswith('+++'):
                        continue  # è·³è¿‡æ–‡ä»¶å…ƒä¿¡æ¯
                    else:
                        current_diff.append(line)

            # ä¿å­˜æœ€åä¸€ä¸ªæ–‡ä»¶çš„diff
            if current_file and current_diff:
                file_diffs[current_file] = '\n'.join(current_diff)

            # åˆå¹¶statå’Œdiffä¿¡æ¯
            for file_path, stats in file_changes.items():
                diff_content = file_diffs.get(file_path, '')

                # æå–å…³é”®çš„diffç‰‡æ®µï¼ˆæœ€å¤šå‰50è¡Œï¼‰
                diff_lines = diff_content.split('\n')[:50] if diff_content else []

                diff_info.append({
                    'file': Path(file_path).name,
                    'file_path': file_path,
                    'additions': stats['additions'],
                    'deletions': stats['deletions'],
                    'changes_summary': stats['changes'],
                    'diff_preview': '\n'.join(diff_lines) if diff_lines else ''
                })

    except Exception as e:
        print(f"âš ï¸ è·å–commit {commit_hash[:8]} çš„diffä¿¡æ¯å¤±è´¥: {e}")

    return diff_info


if __name__ == '__main__':
    import sys
    import os
    from datetime import datetime

    # ä¿®æ”¹å‚æ•°å¤„ç†ï¼Œæ”¯æŒåŸºäºcommits_data.jsonæˆ–ç›´æ¥æŒ‡å®šä»“åº“è·¯å¾„
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python analyze_commits.py <ä»“åº“è·¯å¾„>")
        print("  - å°†åŸºäºå·²å­˜åœ¨çš„ commits_data.json è¿›è¡Œåˆ†æ")
        print("  - å¦‚æœ commits_data.json ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ collect_commits.py")
        print("")
        print("è¾“å‡º:")
        print("  - analysis_result_with_diff.json ä¿å­˜åˆ° skill ç›®å½•")
        sys.exit(1)

    repo_path = sys.argv[1]

    # ç¡®å®šskillç›®å½•è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    skill_dir = os.path.dirname(script_dir)
    commits_data_file = os.path.join(skill_dir, "commits_data.json")

    print("ğŸ” å¼€å§‹åˆ†æGitæäº¤è®°å½•...")

    # æ£€æŸ¥commits_data.jsonæ˜¯å¦å­˜åœ¨
    if not os.path.exists(commits_data_file):
        print(f"âŒ æœªæ‰¾åˆ° {commits_data_file}")
        print("è¯·å…ˆè¿è¡Œ collect_commits.py æ”¶é›†æäº¤æ•°æ®")
        sys.exit(1)

    # è¯»å–commitsæ•°æ®
    print(f"ğŸ“Š è¯»å–æäº¤æ•°æ®: {commits_data_file}")
    try:
        with open(commits_data_file, 'r', encoding='utf-8') as f:
            commits_data = json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–commits_data.jsonå¤±è´¥: {e}")
        sys.exit(1)

    # æ·»åŠ repoä¿¡æ¯
    repo_name = os.path.basename(repo_path)
    for commit in commits_data:
        commit['repo'] = repo_name

    print(f"ğŸ“Š æ‰¾åˆ° {len(commits_data)} ä¸ªæäº¤è®°å½•")

    # ä¸°å¯Œæ•°æ®ï¼ŒåŒ…å«diffåˆ†æ
    print("ğŸ”„ æ­£åœ¨åˆ†ææäº¤æ•°æ®...")
    enriched = enrich_commits(commits_data, FALLBACK_MAPPING, {repo_name: repo_path})

    # ä¸ºæ¯ä¸ªcommitæ·»åŠ diffä¿¡æ¯
    print("ğŸ”„ æ­£åœ¨æå–diffä¿¡æ¯...")
    for commit in enriched:
        commit['diff_info'] = extract_commit_diff(commit, repo_path)

    # åˆ†ç»„
    grouped = group_by_project_and_category(enriched)

    # è¾“å‡ºåˆ†æç»“æœåˆ°skillç›®å½•
    analysis_file = os.path.join(skill_dir, "analysis_result_with_diff.json")
    result = {
        'commits': enriched,
        'grouped': grouped,
        'stats': {
            'total_commits': len(commits_data),
            'effective_commits': len([c for c in enriched if not c.get('_weak', False)]),
            'projects': list(grouped.keys())
        },
        'analysis_timestamp': datetime.now().isoformat(),
        'repo_analyzed': repo_name
    }

    with open(analysis_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"âœ… åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åˆ°: {analysis_file}")

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯åˆ°æ§åˆ¶å°
    print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  - æ€»æäº¤æ•°: {result['stats']['total_commits']}")
    print(f"  - æœ‰æ•ˆæäº¤æ•°: {result['stats']['effective_commits']}")
    print(f"  - æ¶‰åŠé¡¹ç›®: {len(result['stats']['projects'])}")

    for project, categories in grouped.items():
        print(f"\nğŸ“ {project}:")
        for category, commits_list in categories.items():
            effective = len([c for c in commits_list if not c.get('_weak', False)])
            if effective > 0:
                print(f"  â€¢ {category}: {effective} ä¸ª")

    # è¾“å‡ºç®€åŒ–çš„JSONæ•°æ®
    print(f"\nğŸ“„ ç®€åŒ–è¾“å‡ºé¢„è§ˆ:")
    simplified_result = {
        'stats': result['stats'],
        'projects_summary': {project: list(categories.keys()) for project, categories in grouped.items()}
    }
    print(json.dumps(simplified_result, ensure_ascii=False, indent=2))